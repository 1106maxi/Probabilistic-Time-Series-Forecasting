{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "# Please be aware that running this code may yield results different from those       #\n",
    "# reported in my thesis. This difference is due to stochastic weight initialization   #\n",
    "# in LSTMs. Results can therfore vary with each run.                                  #\n",
    "#######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages if needed\n",
    "#pip install yfinance\n",
    "#pip install numpy\n",
    "#pip install pandas\n",
    "#pip install scikit-learn\n",
    "#pip install tensorflow\n",
    "#pip install matplotlib\n",
    "#pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for creating sequential input data\n",
    "def create_lstm_data(data_set_scaled,num_features ,time_steps=1):\n",
    "    X = []\n",
    "\n",
    "    for j in range(num_features):\n",
    "        X.append([])\n",
    "        for i in range(time_steps, data_set_scaled.shape[0]):\n",
    "            X[j].append(data_set_scaled[i-time_steps:i, j])\n",
    "\n",
    "    X=np.moveaxis(X, [0], [2])\n",
    "\n",
    "    X, yi =np.array(X), np.array(data_set_scaled[time_steps:,0])\n",
    "    y=np.reshape(yi,(len(yi),1))\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN:\n",
    "    def __init__(self,ticker,forecasting_window, batch_size = 16 ,time_steps = 10,start_date = \"2009-01-01\",end_date = \"2019-02-01\"):\n",
    "\n",
    "        #Data Collection\n",
    "        self.ticker = ticker\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "\n",
    "        # Data Preparation\n",
    "        self.scaler = StandardScaler() \n",
    "        self.daily_returns_scaled = None\n",
    "        self.daily_prices = None\n",
    "        self.daily_returns = None\n",
    "        self.daily_volume = None\n",
    "        self.daily_returns_sqr = None\n",
    "        self.daily_volume_scaled = None\n",
    "        self.combined_features = None\n",
    "        ###################\n",
    "        self.time_steps = time_steps\n",
    "        ###################\n",
    "        self.train_size = None\n",
    "        self.val_size = None\n",
    "        self.test_size = None\n",
    "        self.x_returns = None\n",
    "        self.x_volume = None\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        self.x_train = None\n",
    "        self.x_test = None\n",
    "        self.x_val = None\n",
    "        self.y_val = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.feature_count = None\n",
    "        self.window = forecasting_window\n",
    "        \n",
    "        # Model Training\n",
    "        self.confidence = 0.9\n",
    "        self.model = None\n",
    "        self.epochs = 100\n",
    "        self.batch_size = batch_size\n",
    "        self.patience = 5\n",
    "        self.sym_loss = [lambda y,f: self.q_loss((1-self.confidence)/2,y,f), lambda y,f: self.q_loss(self.confidence +((1-self.confidence)/2) ,y,f)]\n",
    "\n",
    "\n",
    "        # Model Testing\n",
    "        self.combined_predictions = None\n",
    "        self.all_predictions = None\n",
    "        self.number_of_steps = None\n",
    "        self.y_test_inv = None\n",
    "        self.pred_inv = None\n",
    "        self. eta = 30 #Weighting factor for penalization in the CWC\n",
    "        \n",
    "        # Graphs \n",
    "        self.daily_dates = None\n",
    "        self.dates_test = None\n",
    "\n",
    "        \n",
    "    # Define quantile loss function\n",
    "    def q_loss(self, q, y, f):\n",
    "        e = (y - f)\n",
    "        return K.mean(K.maximum(q * e, (q - 1) * e), axis=-1)\n",
    "\n",
    "    # Function for downloading the data if only the daily returns are used as a feature:\n",
    "    def read_data_return(self):\n",
    "        # Get data from Yahoo Finance\n",
    "        data = yf.download(self.ticker, start=self.start_date, end=self.end_date)\n",
    "\n",
    "        # Extract closing prices \n",
    "        self.daily_prices = data[\"Close\"]\n",
    "\n",
    "        # Calculate the daily return of the stock\n",
    "        self.daily_returns = (self.daily_prices / self.daily_prices.shift(1)) - 1\n",
    "        self.daily_returns = self.daily_returns.dropna()\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            \"Returns\": self.daily_returns\n",
    "        })\n",
    "        self.feature_count = len(df.axes[1])\n",
    "\n",
    "        # Scale the data\n",
    "        scaled_df = self.scaler.fit_transform(df)\n",
    "        \n",
    "        # Create sequential data for the QLSTM\n",
    "        self.x, self.y = create_lstm_data(data_set_scaled = scaled_df,time_steps = self.time_steps, num_features = self.feature_count)\n",
    "\n",
    "        # Split the data into training, validation, and test sets\n",
    "        total_size = len(self.x)\n",
    "        self.train_size = int(total_size * 0.6)\n",
    "        self.val_size = int(total_size * 0.2)\n",
    "        self.test_size = total_size - self.train_size - self.val_size \n",
    "\n",
    "    # Function for downloading the data if the daily returns and the daily trading volume are used as features:\n",
    "    def read_data_return_vol(self):\n",
    "        # Get data from Yahoo Finance\n",
    "        data = yf.download(self.ticker, start=self.start_date, end=self.end_date)\n",
    "        # Extract closing prices and volume\n",
    "        self.daily_prices = data[\"Close\"]\n",
    "        self.volume = data[\"Volume\"]\n",
    "\n",
    "        # Calculate the daily return of the stock\n",
    "        self.daily_returns = (self.daily_prices / self.daily_prices.shift(1)) - 1\n",
    "        self.daily_returns = self.daily_returns.dropna()\n",
    "\n",
    "        # Align volume data with the daily_returns\n",
    "        self.volume = self.volume[self.daily_returns.index]\n",
    "        \n",
    "        self.daily_returns_sqr = self.daily_returns**2\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            \"Returns\": self.daily_returns,\n",
    "            \"Volume\": self.volume[self.daily_returns.index]  # Gleiche Indizes\n",
    "        })\n",
    "        self.feature_count = len(df.axes[1])\n",
    "\n",
    "        # Scale the data\n",
    "        scaled_df = self.scaler.fit_transform(df)\n",
    "        \n",
    "        # Create sequential data for the QLSTM\n",
    "        self.x, self.y = create_lstm_data(data_set_scaled = scaled_df,time_steps = self.time_steps, num_features = self.feature_count)\n",
    "\n",
    "        # Split the data into training, validation, and test sets\n",
    "        total_size = len(self.x)\n",
    "        self.train_size = int(total_size * 0.6)\n",
    "        self.val_size = int(total_size * 0.2)\n",
    "        self.test_size = total_size - self.train_size - self.val_size \n",
    "\n",
    "    # The three model configurations that are tested:\n",
    "    def lstm_model_complex(self, input_shape):\n",
    "        # Input layer\n",
    "        inputs = Input(shape=input_shape) \n",
    "        # Three LSTM layers with 100 neurons each and a dropout rate of 0.1\n",
    "        lstm1 = LSTM(units=100, return_sequences=True,dropout= 0.1)(inputs)\n",
    "        lstm2 = LSTM(units=100, return_sequences=True,dropout= 0.1)(lstm1)\n",
    "        lstm3 = LSTM(units=100,dropout= 0.1)(lstm2)\n",
    "\n",
    "        # Output layers for quantiles\n",
    "        out10 = Dense(1)(lstm3)\n",
    "        out90 = Dense(1)(lstm3)\n",
    "\n",
    "        model = Model(inputs, [out10, out90]) \n",
    "        return model\n",
    "\n",
    "\n",
    "    def lstm_model_mid(self, input_shape):\n",
    "        # Input layer\n",
    "        inputs = Input(shape=input_shape)\n",
    "        # Two LSTM layers with 80 neurons each and a dropout rate of 0.1\n",
    "        lstm1 = LSTM(units=80, return_sequences=True,dropout= 0.1)(inputs)\n",
    "        lstm2 = LSTM(units=80,dropout= 0.1)(lstm1)\n",
    "\n",
    "        # Output layers for quantiles\n",
    "        out10 = Dense(1)(lstm2)\n",
    "        out90 = Dense(1)(lstm2)\n",
    "\n",
    "        model = Model(inputs, [out10, out90])\n",
    "        return model\n",
    "    \n",
    "    def lstm_model_simpler(self, input_shape):\n",
    "        # Input layer\n",
    "        inputs = Input(shape=input_shape)\n",
    "        # One LSTM layers with 25 neurons and a dropout rate of 0.1\n",
    "        lstm1 = LSTM(units=25,dropout= 0.1)(inputs)\n",
    "\n",
    "        # Output layers for quantiles\n",
    "        out10 = Dense(1)(lstm1)\n",
    "        out90 = Dense(1)(lstm1)\n",
    "\n",
    "        model = Model(inputs, [out10, out90])\n",
    "        return model\n",
    "\n",
    "    # Function for updating the training data when the forecasting window is shifted\n",
    "    def update_data_splits(self, i):\n",
    "        roll = i * self.window\n",
    "\n",
    "        self.x_train, self.y_train = self.x[:self.train_size+roll], self.y[:self.train_size+roll]\n",
    "        self.x_val, self.y_val = self.x[self.train_size+roll:self.train_size + self.val_size+roll], self.y[self.train_size+roll:self.train_size + self.val_size+roll]\n",
    "        self.x_test, self.y_test = self.x[self.train_size + self.val_size+roll:self.train_size + self.val_size+roll+self.window], self.y[self.train_size + self.val_size +roll:self.train_size + self.val_size+roll+self.window]\n",
    "\n",
    "        if not isinstance(self.y_train, list) or len(self.y_train) != 2:\n",
    "            self.y_train = [self.y_train, self.y_train] \n",
    "        if not isinstance(self.y_test, list) or len(self.y_test) != 2:\n",
    "            self.y_test = [self.y_test, self.y_test] \n",
    "\n",
    "    # Forecasting function if only the daily returns are used as a feature\n",
    "    def rolling_forecast(self, loss, model):\n",
    "        # Read and prepare data\n",
    "        self.read_data_return()\n",
    "\n",
    "        input_shape = (self.time_steps, self.feature_count)\n",
    "        self.model = model(input_shape) # The medium model is used\n",
    "        \n",
    "        # Compile model with quantile losses\n",
    "        losses = loss\n",
    "        self.model.compile(loss=losses, optimizer=\"adam\", loss_weights=[0.5, 0.5])\n",
    "\n",
    "        stop_early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5) # early stopping \n",
    "        self.number_of_steps = self.test_size // self.window\n",
    "\n",
    "        # Initialize container for combined predictions\n",
    "        self.combined_predictions = [np.empty((0, 1)), np.empty((0, 1))]\n",
    "\n",
    "        for step in range(self.number_of_steps):\n",
    "            # Update the data splits for this window\n",
    "            self.update_data_splits(step)\n",
    "\n",
    "            # Train the model\n",
    "            self.model.fit(self.x_train, self.y_train, \n",
    "                           validation_data=(self.x_val, self.y_val), \n",
    "                           epochs=self.epochs, batch_size=self.batch_size, \n",
    "                           callbacks=[stop_early])\n",
    "\n",
    "            # Make predictions\n",
    "            predictions = self.model.predict(self.x_test)\n",
    "\n",
    "            # Add current predictions to the combined predictions\n",
    "            self.combined_predictions[0] = np.vstack([self.combined_predictions[0], predictions[0]])\n",
    "            self.combined_predictions[1] = np.vstack([self.combined_predictions[1], predictions[1]])\n",
    "    \n",
    "     # Forecasting function if the daily returns and the daily trading volume are used as features\n",
    "    def rolling_forecast_v(self, loss,model):\n",
    "        # Read and prepare data\n",
    "        self.read_data_return_vol()\n",
    "\n",
    "        input_shape = (self.time_steps, self.feature_count)\n",
    "        self.model = model(input_shape) # The medium model is used\n",
    "        \n",
    "        # Compile model with quantile losses\n",
    "        losses = loss\n",
    "        self.model.compile(loss=losses, optimizer=\"adam\", loss_weights=[0.5, 0.5])\n",
    "\n",
    "        stop_early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5) # early stopping \n",
    "        self.number_of_steps = self.test_size // self.window\n",
    "        # Initialize container for combined predictions\n",
    "        self.combined_predictions = [np.empty((0, 1)), np.empty((0, 1))]\n",
    "\n",
    "        for step in range(self.number_of_steps):\n",
    "            # Update the data splits for this window\n",
    "            self.update_data_splits(step)\n",
    "\n",
    "            # Train the model\n",
    "            self.model.fit(self.x_train, self.y_train, \n",
    "                           validation_data=(self.x_val, self.y_val), \n",
    "                           epochs=self.epochs, batch_size=self.batch_size, \n",
    "                           callbacks=[stop_early])\n",
    "\n",
    "            # Make predictions\n",
    "            predictions = self.model.predict(self.x_test)\n",
    "\n",
    "            # Add current predictions to the combined predictions\n",
    "            self.combined_predictions[0] = np.vstack([self.combined_predictions[0], predictions[0]])\n",
    "            self.combined_predictions[1] = np.vstack([self.combined_predictions[1], predictions[1]])\n",
    "\n",
    "    # Test the QLSTM on the test set\n",
    "    def predict_eval(self):\n",
    "        self.y_test = self.y[self.train_size + self.val_size :self.train_size + self.val_size+self.number_of_steps*self.window]\n",
    "        \n",
    "        # Calculate upper and lower bound of the prediction intervals\n",
    "        lower_bound = self.combined_predictions[0]  \n",
    "        upper_bound = self.combined_predictions[1]  \n",
    "\n",
    "        # Calculate the prediction interval normalized average width (PINAW)\n",
    "        n = len(self.y_test)\n",
    "        interval_width_sum = np.sum(upper_bound - lower_bound)\n",
    "        y_range = np.max(self.y_test) - np.min(self.y_test)\n",
    "        pinaw = interval_width_sum / (n * y_range)\n",
    "        \n",
    "        # Calculate the prediction interval coverage probability (PICP)\n",
    "        within_interval = np.sum((self.y_test >= lower_bound) & (self.y_test <= upper_bound))\n",
    "        picp = within_interval / n\n",
    "\n",
    "        # Calculate Coverage Width-based Criterion (CWC)\n",
    "            # Eta is the weighting factor for penalization\n",
    "        cwc = (1 - pinaw) * np.exp(-self.eta * (picp - (self.confidence))**2)\n",
    "        \n",
    "        return {\n",
    "            \"batch size\": self.batch_size,\n",
    "            \"time steps\": self.time_steps,\n",
    "            \"ticker\": self.ticker,\n",
    "            \"interval_width_sum\":interval_width_sum,\n",
    "            \"within_interval\":within_interval,\n",
    "            \"LSTM CWC\": cwc,\n",
    "            \"LSTM PINAW\": pinaw,\n",
    "            \"LSTM PICP\": picp,\n",
    "        }\n",
    " \n",
    "    # Function for plotting the results \n",
    "    def graph(self):\n",
    "\n",
    "        self.pred_inv = [\n",
    "        self.scaler.inverse_transform(self.combined_predictions[0].reshape(-1, 1)),\n",
    "        self.scaler.inverse_transform(self.combined_predictions[1].reshape(-1, 1))\n",
    "        ]\n",
    "       \n",
    "        self.y_test_inv = self.daily_returns[self.train_size + self.val_size:self.train_size + self.val_size + self.number_of_steps*self.window]\n",
    "        \n",
    "        self.daily_dates = self.daily_returns.index[self.train_size + self.val_size:self.train_size + self.val_size + self.number_of_steps*self.window]\n",
    "        \n",
    "\n",
    "        plt.figure(figsize=(14, 5))\n",
    "        plt.plot(self.daily_dates, self.y_test_inv, label=\"Actual Daily Return \", color=\"black\")\n",
    "        plt.plot(self.daily_dates, self.pred_inv[0], label=f\"Predicted Return (Quantile {round(((1-self.confidence)/2)*100,0)}%)\", linestyle=\"dotted\", color = \"purple\")\n",
    "        plt.plot(self.daily_dates, self.pred_inv[1], label=f\"Predicted Return (Quantile {(self.confidence +((1-self.confidence)/2))*100}%)\", linestyle=\"dotted\", color = \"green\")\n",
    "\n",
    "        y1 = self.pred_inv[0].ravel()  \n",
    "        y2 = self.pred_inv[1].ravel()  \n",
    "\n",
    "        plt.fill_between(self.daily_dates, y1, y2, where=(y2 >= y1), color=\"red\", alpha=0.3)\n",
    "\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Daily Return\")\n",
    "        plt.legend(loc=\"upper right\") \n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with the stock of Boeing:\n",
    "QLSTM_test = ANN(\"BA\",start_date=\"2012-05-03\",end_date= \"2015-09-01\",time_steps =15, batch_size = 32,forecasting_window = 10)\n",
    "QLSTM_test.rolling_forecast(loss= QLSTM_test.sym_loss,model = QLSTM_test.lstm_model_mid)\n",
    "QLSTM_test.predict_eval()\n",
    "QLSTM_test.graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the start of the test set for each period so it can be excluded from the hyperparameter tuning:\n",
    "\n",
    "# The start and end dates of the three study periods\n",
    "start_dates = [\"2009-01-01\", \"2012-05-02\", \"2015-09-01\"]\n",
    "end_dates = [\"2012-05-02\", \"2015-09-01\", \"2019-01-01\"]\n",
    "\n",
    "# Loop through each pair of start and end dates\n",
    "for i,(start, end) in enumerate(zip(start_dates, end_dates)):\n",
    "\n",
    "    # Convert the start and end dates to datetime format\n",
    "    start_date = pd.to_datetime(start)\n",
    "    end_date = pd.to_datetime(end)\n",
    "    \n",
    "    # Calculate the total duration between the start and end date\n",
    "    total_duration = end_date - start_date\n",
    "    \n",
    "    # The test period will be the last 20% of the total period\n",
    "    test_duration = total_duration * 0.2\n",
    "    \n",
    "    # The start of the test period will be at 80% of the total period\n",
    "    test_date = end_date - test_duration\n",
    "    \n",
    "    # Print the start of the test period\n",
    "    print(f\"Start of test period {i+1}: {test_date.date()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code used for testing the three different QLSTM architectures:\n",
    "\n",
    "time_steps = [5, 10, 15, 20, 25, 30]\n",
    "batch_size = [16, 32, 64, 128]\n",
    "\n",
    "# United Parcel Service for the first study period\n",
    "results_ups_simp = []\n",
    "for rep in range(1):\n",
    "    for time in time_steps:\n",
    "        for batch in batch_size:\n",
    "                    QLSTM_opt = ANN(\"UPS\",start_date=\"2009-01-01\",end_date= \"2011-09-01\",time_steps =time, batch_size = batch,forecasting_window = 10)\n",
    "                    QLSTM_opt.rolling_forecast(loss= QLSTM_opt.sym_loss, model= QLSTM_opt.lstm_model_simpler)\n",
    "                    result = QLSTM_opt.predict_eval()\n",
    "                    results_ups_simp.append({\n",
    "                        \"time steps\": result[\"time steps\"],\n",
    "                        \"batch size\": result[\"batch size\"],\n",
    "                        \"CWC\": result[\"LSTM CWC\"]\n",
    "                    })\n",
    "\n",
    "df_results_ups_simp = pd.DataFrame(results_ups_simp)\n",
    "#df_results_ups_simp.to_csv(\"ups_simple.csv\", index=False)\n",
    "print(df_results_ups_simp)\n",
    "\n",
    "\n",
    "results_ups_mid = []\n",
    "for rep in range(9):\n",
    "    for time in time_steps:\n",
    "        for batch in batch_size:\n",
    "                    QLSTM_opt = ANN(\"UPS\",start_date=\"2009-01-01\",end_date= \"2011-09-01\",time_steps =time, batch_size = batch,forecasting_window = 10)\n",
    "                    QLSTM_opt.rolling_forecast(loss= QLSTM_opt.sym_loss, model= QLSTM_opt.lstm_model_mid)\n",
    "                    result = QLSTM_opt.predict_eval()\n",
    "                    results_ups_mid.append({\n",
    "                        \"time steps\": result[\"time steps\"],\n",
    "                        \"batch size\": result[\"batch size\"],\n",
    "                        \"CWC\": result[\"LSTM CWC\"]\n",
    "                    })\n",
    "\n",
    "df_results_ups_mid = pd.DataFrame(results_ups_mid)\n",
    "#df_results_ups_mid.to_csv(\"ups_medium.csv\", index=False)\n",
    "print(df_results_ups_mid)\n",
    "\n",
    "\n",
    "results_ups_comp = []\n",
    "for rep in range(9):\n",
    "    for time in time_steps:\n",
    "        for batch in batch_size:\n",
    "                    QLSTM_opt = ANN(\"UPS\",start_date=\"2009-01-01\",end_date= \"2011-09-01\",time_steps =time, batch_size = batch,forecasting_window = 10)\n",
    "                    QLSTM_opt.rolling_forecast(loss= QLSTM_opt.sym_loss, model= QLSTM_opt.lstm_model_complex)\n",
    "                    result = QLSTM_opt.predict_eval()\n",
    "                    results_ups_comp.append({\n",
    "                        \"time steps\": result[\"time steps\"],\n",
    "                        \"batch size\": result[\"batch size\"],\n",
    "                        \"CWC\": result[\"LSTM CWC\"]\n",
    "                    })\n",
    "\n",
    "df_results_ups_comp = pd.DataFrame(results_ups_comp)\n",
    "#df_results_ups_comp.to_csv(\"ups_complex.csv\", index=False)\n",
    "print(df_results_ups_comp)\n",
    "\n",
    "# Waste Management for the second study period\n",
    "results_wm_simp = []\n",
    "for rep in range(9):\n",
    "    for time in time_steps:\n",
    "        for batch in batch_size:\n",
    "                    QLSTM_opt = ANN(\"WM\",start_date=\"2012-05-02\",end_date= \"2014-12-31\",time_steps =time, batch_size = batch,forecasting_window = 10)\n",
    "                    QLSTM_opt.rolling_forecast(loss= QLSTM_opt.sym_loss, model= QLSTM_opt.lstm_model_simpler)\n",
    "                    result = QLSTM_opt.predict_eval()\n",
    "                    results_ups_simp.append({\n",
    "                        \"time steps\": result[\"time steps\"],\n",
    "                        \"batch size\": result[\"batch size\"],\n",
    "                        \"CWC\": result[\"LSTM CWC\"]\n",
    "                    })\n",
    "\n",
    "df_results_wm_simp = pd.DataFrame(results_wm_simp)\n",
    "#df_results_wm_simp.to_csv(\"wm_simple.csv\", index=False)\n",
    "print(df_results_wm_simp)\n",
    "\n",
    "results_wm_mid = []\n",
    "for rep in range(9):\n",
    "    for time in time_steps:\n",
    "        for batch in batch_size:\n",
    "                    QLSTM_opt = ANN(\"WM\",start_date=\"2012-05-02\",end_date= \"2014-12-31\",time_steps =time, batch_size = batch,forecasting_window = 10)\n",
    "                    QLSTM_opt.rolling_forecast(loss= QLSTM_opt.sym_loss, model= QLSTM_opt.lstm_model_mid)\n",
    "                    result = QLSTM_opt.predict_eval()\n",
    "                    results_ups_mid.append({\n",
    "                       \"time steps\": result[\"time steps\"],\n",
    "                        \"batch size\": result[\"batch size\"],\n",
    "                        \"CWC\": result[\"LSTM CWC\"]\n",
    "                    })\n",
    "\n",
    "df_results_wm_mid = pd.DataFrame(results_wm_mid)\n",
    "#df_results_wm_mid.to_csv(\"wm_medium.csv\", index=False)\n",
    "print(df_results_wm_mid)\n",
    "\n",
    "results_wm_comp = []\n",
    "for rep in range(9):\n",
    "    for time in time_steps:\n",
    "        for batch in batch_size:\n",
    "                    QLSTM_opt = ANN(\"WM\",start_date=\"2012-05-02\",end_date= \"2014-12-31\",time_steps =time, batch_size = batch,forecasting_window = 10)\n",
    "                    QLSTM_opt.rolling_forecast(loss= QLSTM_opt.sym_loss, model= QLSTM_opt.lstm_model_complex)\n",
    "                    result = QLSTM_opt.predict_eval()\n",
    "                    results_ups_comp.append({\n",
    "                        \"time steps\": result[\"time steps\"],\n",
    "                        \"batch size\": result[\"batch size\"],\n",
    "                        \"CWC\": result[\"LSTM CWC\"]\n",
    "                    })\n",
    "\n",
    "df_results_wm_comp = pd.DataFrame(results_wm_comp)\n",
    "#df_results_wm_comp.to_csv(\"wm_complex.csv\", index=False)\n",
    "print(df_results_wm_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code used for testing different features:\n",
    "\n",
    "# Start and end dates for the three study periods without their test sets\n",
    "start_dates =[\"2009-01-01\", \"2012-05-02\", \"2015-09-01\"]\n",
    "end_dates = [\"2011-09-01\", \"2014-12-31\", \"2018-05-02\"]\n",
    "\n",
    "industrials_stocks = [\"BA\", \"CHRW\", \"DOV\", \"EFX\", \"EMR\", \"FAST\", \"ITW\", \"NOC\", \"UPS\", \"WM\"]\n",
    "\n",
    "results_return = []\n",
    "for rep in range(9):\n",
    "    for i in range(len(start_dates)):\n",
    "        for stock in industrials_stocks:\n",
    "                    QLSTM_opt = ANN(stock,start_date=start_dates[i],end_date= end_dates[i],time_steps =15, batch_size = 32,forecasting_window = 10)\n",
    "                    QLSTM_opt.rolling_forecast(loss= QLSTM_opt.sym_loss, model = QLSTM_opt.lstm_model_mid)\n",
    "                    result = QLSTM_opt.predict_eval()\n",
    "                    results_return.append({\n",
    "                        \"interval_width_sum\":result[\"interval_width_sum\"],\n",
    "                        \"within_interval\":result[\"within_interval\"],\n",
    "                        \"PINAW\": result[\"LSTM PINAW\"],\n",
    "                        \"PICP\": result[\"LSTM PICP\"],\n",
    "                        \"CWC\": result[\"LSTM CWC\"],\n",
    "                        \"Stock\": QLSTM_opt.ticker,\n",
    "                        \"Study Period\": i + 1\n",
    "                    })\n",
    "\n",
    "    df_return = pd.DataFrame(results_return)\n",
    "        \n",
    "    #file_name = f\"f_return_p{i+1}.csv\"  \n",
    "    #df_return.to_csv(file_name, index=False)\n",
    "    print(df_return)\n",
    "\n",
    "\n",
    "\n",
    "results_return_vol = []\n",
    "for rep in range(9):\n",
    "    for i in range(len(start_dates)):\n",
    "        for stock in industrials_stocks:\n",
    "                    QLSTM_opt = ANN(stock,start_date=start_dates[i],end_date= end_dates[i],time_steps =15, batch_size = 32,forecasting_window = 10)\n",
    "                    QLSTM_opt.rolling_forecast_v(loss= QLSTM_opt.sym_loss, model = QLSTM_opt.lstm_model_mid)\n",
    "                    result = QLSTM_opt.predict_eval()\n",
    "                    results_return_vol.append({\n",
    "                        \"interval_width_sum\":result[\"interval_width_sum\"],\n",
    "                        \"within_interval\":result[\"within_interval\"],\n",
    "                        \"PINAW\": result[\"LSTM PINAW\"],\n",
    "                        \"PICP\": result[\"LSTM PICP\"],\n",
    "                        \"CWC\": result[\"LSTM CWC\"],\n",
    "                        \"Stock\": QLSTM_opt.ticker,\n",
    "                        \"Study Period\": i + 1 \n",
    "                    })\n",
    "\n",
    "\n",
    "    df_return_vol = pd.DataFrame(results_return_vol)\n",
    "        \n",
    "    #file_name = f\"f_return_vol_p{i+1}.csv\"  \n",
    "    #df_return_vol.to_csv(file_name, index=False)\n",
    "    print(df_return_vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code used for the final testing of all stocks:\n",
    "\n",
    "# Start and end dates of the three study periods\n",
    "start_dates =[\"2009-01-01\", \"2012-05-02\", \"2015-09-01\"]\n",
    "end_dates = [\"2012-05-02\", \"2015-09-01\", \"2019-01-01\"]\n",
    "\n",
    "industrials_stocks = [\"BA\", \"CHRW\", \"DOV\", \"EFX\", \"EMR\", \"FAST\", \"ITW\", \"NOC\", \"UPS\", \"WM\"]\n",
    "\n",
    "results = []\n",
    "for rep in range(9):\n",
    "    for i in range(len(start_dates)):\n",
    "        for stock in industrials_stocks:\n",
    "                    QLSTM_opt = ANN(stock,start_date=start_dates[i],end_date= end_dates[i],time_steps =15, batch_size = 32,forecasting_window = 10)\n",
    "                    QLSTM_opt.rolling_forecast_v(loss= QLSTM_opt.sym_loss, model = QLSTM_opt.lstm_model_mid)\n",
    "                    result = QLSTM_opt.predict_eval()\n",
    "                    results.append({\n",
    "                        \"interval_width_sum\":result[\"interval_width_sum\"],\n",
    "                        \"within_interval\":result[\"within_interval\"],\n",
    "                        \"LSTM PINAW\": result[\"LSTM PINAW\"],\n",
    "                        \"LSTM PICP\": result[\"LSTM PICP\"],\n",
    "                        \"CWC\": result[\"LSTM CWC\"],\n",
    "                        \"Stock\": QLSTM_opt.ticker,\n",
    "                        \"Study Period\": i + 1\n",
    "                    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "#df_results.to_csv(final_results_QLSTM, index=False)\n",
    "print(df_results)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results for the three different QLSTM architectures:\n",
    "\n",
    "stocks = [\"wm\", \"ups\"]\n",
    "\n",
    "# Loop through each stock and generate the plot\n",
    "for stock in stocks:\n",
    "    # Read CSV files dynamically based on the stock\n",
    "    df_simple = pd.read_csv(f\"QLSTM_hyperparameter_results/{stock}_simple.csv\")\n",
    "    df_mid = pd.read_csv(f\"QLSTM_hyperparameter_results/{stock}_medium.csv\")\n",
    "    df_complex = pd.read_csv(f\"QLSTM_hyperparameter_results/{stock}_complex.csv\")\n",
    "\n",
    "    # Add a new column to identify the model type\n",
    "    df_simple[\"model\"] = \"Simple\"\n",
    "    df_mid[\"model\"] = \"Medium\"\n",
    "    df_complex[\"model\"] = \"Complex\"\n",
    "\n",
    "    # Combine the DataFrames\n",
    "    df_combined = pd.concat([df_simple, df_mid, df_complex], ignore_index=True)\n",
    "\n",
    "    # Create a categorical column for \"time steps\"\n",
    "    df_combined[\"time steps\"] = df_combined[\"time steps\"].astype(\"category\")\n",
    "\n",
    "    # Create the boxplot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Use Seaborn for the boxplot with color assignment based on \"time steps\"\n",
    "    sns.boxplot(x=\"model\", y=\"CWC\", hue=\"time steps\", data=df_combined, palette=\"mako\", whis=(0, 100))\n",
    "\n",
    "    # Set plot configurations\n",
    "    plt.xlabel(\"Model\",fontsize = 20)\n",
    "    plt.ylabel(\"CWC\", fontsize = 18)\n",
    "    plt.xticks(rotation=45, fontsize=18)  \n",
    "    plt.yticks(fontsize=14)  \n",
    "    plt.legend(title=\"Time Steps\", fontsize = 13)\n",
    "\n",
    "    # Adjust layout and save the plot\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(f\"boxplot_time_QLSTM_comparison_{stock}.png\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results for the three different QLSTM architectures:\n",
    "\n",
    "stocks = [\"wm\", \"ups\"]\n",
    "\n",
    "# Loop through each stock and generate the plot\n",
    "for stock in stocks:\n",
    "    # Read CSV files dynamically based on the stock\n",
    "    df_simple = pd.read_csv(f\"QLSTM_hyperparameter_results/{stock}_simple.csv\")\n",
    "    df_mid = pd.read_csv(f\"QLSTM_hyperparameter_results/{stock}_medium.csv\")\n",
    "    df_complex = pd.read_csv(f\"QLSTM_hyperparameter_results/{stock}_complex.csv\")\n",
    "\n",
    "    # Add a new column to identify the model type\n",
    "    df_simple[\"model\"] = \"Simple\"\n",
    "    df_mid[\"model\"] = \"Medium\"\n",
    "    df_complex[\"model\"] = \"Complex\"\n",
    "\n",
    "    # Combine the DataFrames\n",
    "    df_combined = pd.concat([df_simple, df_mid, df_complex], ignore_index=True)\n",
    "\n",
    "    # Create a categorical column for \"time steps\"\n",
    "    df_combined[\"batch size\"] = df_combined[\"batch size\"].astype(\"category\")\n",
    "\n",
    "    # Create the boxplot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Use Seaborn for the boxplot with color assignment based on \"time steps\"\n",
    "    sns.boxplot(x=\"model\", y=\"CWC\", hue=\"batch size\", data=df_combined, palette=\"viridis\", whis=(0, 100))\n",
    "\n",
    "    # Set plot configurations\n",
    "    plt.xlabel(\"Model\",fontsize = 20)\n",
    "    plt.ylabel(\"CWC\", fontsize = 18)\n",
    "    plt.xticks(rotation=45, fontsize=18)  \n",
    "    plt.yticks(fontsize=14)  \n",
    "    plt.legend(title=\"Batch Size\", fontsize = 13)\n",
    "\n",
    "    # Adjust layout and save the plot\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(f\"boxplot_time_QLSTM_comparison_{stock}.png\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting excerpt of the comparison of different features:\n",
    "\n",
    "stocks = [\"EFX\", \"EMR\"]\n",
    "\n",
    "# Read CSV files \n",
    "df_return = pd.read_csv(\"QLSTM_features_results/f_return_p1.csv\")\n",
    "df_return_vol = pd.read_csv(\"QLSTM_features_results/f_return_vol_p1.csv\")\n",
    "\n",
    "# Add model type column\n",
    "df_return[\"model\"] = \"Daily Returns\"\n",
    "df_return_vol[\"model\"] = \"Volume and Daily Returns\"\n",
    "\n",
    "# Combine the data frames\n",
    "df_combined = pd.concat([df_return, df_return_vol], ignore_index=True)\n",
    "\n",
    "\n",
    "# Loop through stocks\n",
    "for  stock in stocks:\n",
    "\n",
    "    # Create the plot \n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    # Filter for the current stock  \n",
    "    df_filtered = df_combined[df_combined[\"Stock\"] == stock]\n",
    "\n",
    "    # Create boxplot\n",
    "    sns.boxplot(x=\"model\", y=\"CWC\", hue=\"model\", palette=\"mako\", data=df_filtered,whis=(0, 100))\n",
    "    plt.xlabel(\"Features\")\n",
    "    plt.ylabel(\"CWC\")\n",
    "    \n",
    "    # Adjust layout and display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results for the comparison of different features:\n",
    "\n",
    "study_periods = [1, 2, 3]\n",
    "stocks = [\"BA\", \"UPS\", \"WM\", \"DOV\", \"NOC\", \"EMR\", \"ITW\", \"CHRW\", \"FAST\", \"EFX\"]\n",
    "\n",
    "# Loop through all study periods\n",
    "for period in study_periods:\n",
    "    # Read CSV files for the current study period\n",
    "    df_return = pd.read_csv(f\"QLSTM_features_results/f_return_p{period}.csv\")\n",
    "    df_return_vol = pd.read_csv(f\"QLSTM_features_results/f_return_vol_p{period}.csv\")\n",
    "\n",
    "    # Add model type column\n",
    "    df_return[\"model\"] = \"Daily Returns\"\n",
    "    df_return_vol[\"model\"] = \"Volume and Daily Returns\"\n",
    "\n",
    "    # Combine the data frames\n",
    "    df_combined = pd.concat([df_return, df_return_vol], ignore_index=True)\n",
    "\n",
    "    # Create the plot\n",
    "    fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(18, 12))\n",
    "    axes = axes.flatten()  # Flatten axes array for easy iteration\n",
    "\n",
    "    # Loop through each stock\n",
    "    for i, stock in enumerate(stocks):\n",
    "        # Filter data for the current stock\n",
    "        df_filtered = df_combined[df_combined[\"Stock\"] == stock]\n",
    "\n",
    "        # Create boxplot\n",
    "        sns.boxplot(x=\"model\", y=\"CWC\", hue=\"model\", palette=\"mako\", data=df_filtered, ax=axes[i], whis=(0, 100))\n",
    "        axes[i].set_title(stock)\n",
    "        axes[i].set_xlabel(\"Features\")\n",
    "        axes[i].set_ylabel(\"CWC\")\n",
    "\n",
    "    # Remove unused axes\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    # Adjust layout and display plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving the final results of the comparison between QLSTM and GARCH:\n",
    "\n",
    "results_comp = pd.read_csv(\"Final_comparison_results/final_results_QLSTM.csv\")\n",
    "results_comp_2 = pd.read_csv(\"Final_comparison_results/final_results_GARCH.csv\")\n",
    "\n",
    "for period in sorted(results_comp[\"Period\"].unique()):\n",
    "    period_df = results_comp[results_comp[\"Period\"] == period]\n",
    "    period_df_2 = results_comp_2[results_comp_2[\"Period\"] == period]\n",
    "    \n",
    "    stats_df = period_df.groupby(\"Stock\").agg(\n",
    "        Best=(\"CWC\", \"max\"),\n",
    "        Mean=(\"CWC\", \"mean\"),\n",
    "        std=(\"CWC\", \"std\")\n",
    "    ).reset_index()\n",
    "    \n",
    "    stats_df_garch = period_df_2.groupby(\"Stock\").agg(\n",
    "    Result=(\"CWC\", \"max\"),\n",
    "    ).reset_index()\n",
    "\n",
    "    print(f\"Results for period {period}:\\n\", stats_df, \"\\n\")\n",
    "    print(stats_df_garch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the PICP and PINAW for the QLSTM and GARCH:\n",
    "\n",
    "results_comp = pd.read_csv(\"Final_comparison_results/final_results_QLSTM.csv\")\n",
    "results_comp_2 = pd.read_csv(\"Final_comparison_results/final_results_GARCH.csv\")\n",
    "\n",
    "# Add a column to identify the model\n",
    "results_comp[\"Model\"] = \"QLSTM\"\n",
    "results_comp_2[\"Model\"] = \"GARCH\"\n",
    "\n",
    "# Concatenate the two datasets\n",
    "combined_results = pd.concat([results_comp, results_comp_2])\n",
    "\n",
    "# Reset the index to avoid duplicate index issues\n",
    "combined_results.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Get unique periods from the dataset\n",
    "unique_periods = combined_results[\"Period\"].unique()\n",
    "\n",
    "# Loop through all periods\n",
    "for period in unique_periods:\n",
    "    # Filter data for the current period\n",
    "    period_data = combined_results[combined_results[\"Period\"] == period]\n",
    "\n",
    "    # Plotting \"PINAW\" vs \"PICP\" in a 2D scatter plot for the current period\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.scatterplot(x=\"PINAW\", y=\"PICP\", hue=\"Model\", style=\"Stock\", data=period_data, palette=\"Set2\")\n",
    "\n",
    "    # Add a horizontal line at y = 0.9\n",
    "    plt.axhline(y=0.9, color=\"grey\", linestyle=\"--\", linewidth=1)\n",
    "\n",
    "    # Adjust legend to only show model names\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    model_handles = [handle for handle, label in zip(handles, labels) if label in [\"QLSTM\", \"GARCH\"]]\n",
    "    model_labels = [label for label in labels if label in [\"QLSTM\", \"GARCH\"]]\n",
    "    plt.legend(model_handles, model_labels, title=\"Model\", loc=\"upper left\", bbox_to_anchor=(0, 1))\n",
    "\n",
    "    # Set the labels\n",
    "    plt.xlabel(\"PINAW\")\n",
    "    plt.ylabel(\"PICP\")\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a legend for the stocks:     \n",
    "\n",
    "# Read the data\n",
    "results_comp = pd.read_csv(\"Final_comparison_results/final_results_QLSTM.csv\")\n",
    "results_comp_2 = pd.read_csv(\"Final_comparison_results/final_results_GARCH.csv\")\n",
    "\n",
    "# Combine the datasets\n",
    "combined_results = pd.concat([results_comp, results_comp_2])\n",
    "\n",
    "# Plot just to get the handles and labels (no need to show the plot)\n",
    "scatter = sns.scatterplot(x=\"PINAW\", y=\"PICP\", style=\"Stock\", data=combined_results, color = \"black\")\n",
    "\n",
    "# Extract the handles and labels for the stocks only (ignore QLSTM and GARCH)\n",
    "handles, labels = scatter.get_legend_handles_labels()\n",
    "stock_handles = [handle for handle, label in zip(handles, labels) if label not in [\"QLSTM\", \"GARCH\"]]\n",
    "stock_labels = [label for label in labels if label not in [\"QLSTM\", \"GARCH\"]]\n",
    "\n",
    "# Create and display the stock legend separately\n",
    "fig_legend = plt.figure(figsize=(0.5, 6))\n",
    "fig_legend.legend(stock_handles, stock_labels, title=\"Stock\", loc=\"center\", frameon=True)\n",
    "    \n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
